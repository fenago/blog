{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "python-text-mining",
      "graded_item_id": "Pn19K",
      "launcher_item_id": "y1juS",
      "part_id": "ctlgo"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "spam_message_prediction.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP-qS-hyTdvZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acA9_sZCH00S"
      },
      "source": [
        "spam_data = pd.read_csv(\"spam.csv\", engine='python')\n",
        "\n",
        "spam_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQfuhg58W8x2"
      },
      "source": [
        "spam_data = spam_data[['v1', 'v2']]                         #deleting unnecessary columns\n",
        "spam_data['target'] = np.where(spam_data['v1']=='spam',1,0) #converting target column to binary\n",
        "\n",
        "del spam_data['v1']\n",
        "\n",
        "spam_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "EEX8uCnyTdvb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(spam_data['v2'], \n",
        "                                                    spam_data['target'], \n",
        "                                                    random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3i0zfZATdvc"
      },
      "source": [
        "print(len(spam_data[spam_data['target']==1])/len(spam_data['target'])*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGk4ekdJTdve"
      },
      "source": [
        "#CountVectorizer || Longest Token in vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "y7NCuVh9Tdvf"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# List all tokens and their counts as a dictionary:\n",
        "vocabulary = CountVectorizer().fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17zmk_itZd9F"
      },
      "source": [
        "vocabulary.vocabulary_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRxqjrV1Zgxd"
      },
      "source": [
        "# You want only the keys, i.e, the words:\n",
        "vocabulary = [x for x in vocabulary.vocabulary_.keys()]\n",
        "    \n",
        "# Store the lengths in a separate list:\n",
        "len_vocabulary = [len(x) for x in vocabulary]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVWpn8kJZkxM"
      },
      "source": [
        "# Use the index of the longest token:\n",
        "vocabulary[np.argmax(len_vocabulary)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDFFcj-sTdvg"
      },
      "source": [
        "#Fitting a multinomial Naive Bayes classifier model with smoothing `alpha=0.1'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "wVYgKo3LTdvh"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "cv = CountVectorizer().fit(X_train)\n",
        "    \n",
        "# Transform both X_train and X_test with the same CV object:\n",
        "X_train_cv = cv.transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)\n",
        "    \n",
        "# Classifier for prediction:\n",
        "clf = MultinomialNB(alpha=0.1)\n",
        "clf.fit(X_train_cv, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q33PWbxla4cO"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "preds_test = clf.predict(X_test_cv)\n",
        "print(roc_auc_score(y_test, preds_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "L5DPiveRTdvk"
      },
      "source": [
        "#ignoring terms with a doc freq less than 5\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tf = TfidfVectorizer(min_df=5).fit(X_train)\n",
        "X_train_tf = tf.transform(X_train)\n",
        "X_test_tf = tf.transform(X_test)\n",
        "\n",
        "clf = MultinomialNB(alpha=0.1)\n",
        "clf.fit(X_train_tf, y_train)\n",
        "pred = clf.predict(X_test_tf)\n",
        "print(roc_auc_score(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pFbgWdyeH11"
      },
      "source": [
        "newpred = ['congratulations you have earned 10 thousand dollars']\n",
        "newpred_tf = tf.transform(newpred)\n",
        "\n",
        "if str(clf.predict(newpred_tf)) == '[1]':\n",
        "  print('Its a spam!')\n",
        "\n",
        "else:\n",
        "  print('Not a spam.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewRln6i1VgdN"
      },
      "source": [
        "newpred = ['Hi Muneeb, how are you doing?']\n",
        "newpred_tf = tf.transform(newpred)\n",
        "\n",
        "if str(clf.predict(newpred_tf)) == '[1]':\n",
        "  print('Its a spam!')\n",
        "\n",
        "else:\n",
        "  print('Not a spam.')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}